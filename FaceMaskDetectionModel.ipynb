{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceMaskDetectionModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOFYSs7j8zlG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "042lro5C92SJ",
        "outputId": "d6b0ec9d-d668-41ee-b6a1-90245d60c2b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -uq \"/content/drive/My Drive/facemask/archive\" -d \"/content/drive/My Drive/facemask/archive\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLtSgXUX-TjN",
        "outputId": "ba80b213-c0be-429b-87ab-bd758cb39f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/drive/My Drive/facemask/archive, /content/drive/My Drive/facemask/archive.zip or /content/drive/My Drive/facemask/archive.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "main_dir = '/content/drive/My Drive/facemask/archive/New Masks Dataset'\n",
        "train_dir = os.path.join(main_dir,'Train')\n",
        "test_dir = os.path.join(main_dir,'Test')\n",
        "valid_dir = os.path.join(main_dir,'Validation')\n",
        "\n",
        "train_mask_dir = os.path.join(train_dir,'Mask')\n",
        "train_nomask_dir = os.path.join(train_dir,'Non Mask')"
      ],
      "metadata": {
        "id": "OXu_Epj9Bxyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKEH_nhsC7jb",
        "outputId": "5c03ef58-10c8-4dfd-e3fe-fa535817453d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/facemask/archive/New Masks Dataset/Train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask_names = os.listdir(train_mask_dir)\n",
        "print(train_mask_names)\n",
        "\n",
        "train_nomask_names = os.listdir(train_nomask_dir)\n",
        "print(train_nomask_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvJxJibODBDQ",
        "outputId": "710d7301-f9c3-4263-ad21-e1c849f98c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0003.jpg', '0006.jpg', '0048.jpg', '0113.jpg', '0091.jpg', '0063.jpg', '0150.jpg', '0160.jpg', '0022.jpg', '0129.png', '0127.jpg', '0121.png', '0125.jpeg', '0043.jpg', '0029.jpg', '0115.jpg', '0153.jpg', '0042.jpg', '0112.png', '0116.png', '0097.png', '0066.jpg', '0055.jpg', '0126.jpg', '0128.png', '0158.jpg', '0037.jpg', '0110.jpg', '0019.jpg', '0040.jpg', '0018.jpg', '0027.jpg', '0170.jpg', '0343.jpg', '0267.jpg', '0273.jpg', '0200.jpg', '0250.png', '0188.jpg', '0168.png', '0317.jpg', '0323.jpg', '0309.jpg', '0202.jpg', '0211.jpg', '0201.jpg', '0257.jpg', '0286.jpg', '0277.jpg', '0311.jpeg', '0166.jpg', '0216.jpg', '0212.jpg', '0249.jpg', '0241.jpg', '0243.jpg', '0161.jpg', '0247.jpg', '0198.jpg', '0171.jpg', '0220.jpg', '0190.jpg', '0205.jpg', '0197.png', '0269.jpg', '0488.jpg', '0502.png', '0376.png', '0499.jpg', '0486.jpg', '0420.jpeg', '0451.jpg', '0367.png', '0498.jpg', '0415.jpg', '0503.png', '0427.jpg', '0384.jpg', '0482.jpg', '0421.jpg', '0469.jpg', '0385.jpg', '0417.jpg', '0481.jpg', '0414.jpg', '0470.jpg', '0493.jpg', '0372.jpg', '0505.jpg', '0466.jpg', '0387.png', '0418.jpg', '0657.jpg', '0544.jpg', '0583.jpg', '0506.jpg', '0669.jpg', '0566.jpg', '0515.png', '0690.jpg', '0638.jpg', '0558.jpg', '0671.jpg', '0644.jpg', '0693.jpg', '0614.jpg', '0559.jpg', '0655.jpg', '0582.jpg', '0698.jpg', '0592.jpg', '0676.jpg', '0561.jpg', '0661.jpg', '0536.jpg', '0545.jpg', '0650.jpg', '0639.jpg', '0547.jpg', '0660.jpg', '0626.jpg', '0577.jpg', '0782.jpg', '0787.jpg', '0760.jpg', '0727.jpg', '0784.jpg', '0714.jpg', '0737.jpg', '0777.jpg', '0759.jpg', '0761.jpg', '0733.jpg', '0748.jpg', '0746.jpg', '0769.jpg', '0770.jpg', '0763.jpg', '0715.jpg', '0779.jpg', '0772.jpg', '0750.jpg', '0725.jpg', '0791.jpg', '0786.jpg', '0743.jpg', '0773.jpg', '0802.jpg', '0780.jpg', '0792.jpg', '0719.jpg', '0726.jpg', '0803.jpg', '0731.jpg', '0805.jpg', '0943.jpg', '0934.png', '0938.jpeg', '0936.jpg', '0932.jpg', '1020.jpg', '0901.jpeg', '1037.png', '0913.jpg', '0976.jpg', '0930.jpg', '0831.jpg', '0972.jpg', '1039.jpg', '0838.jpg', '0951.jpg', '0837.jpg', '0954.jpg', '0888.jpg', '0862.jpg', '0988.jpg', '1036.png', '0999.png', '0891.jpg', '0994.jpg', '0911.jpg', '0806.jpg', '0864.jpg', '1115.jpg', '1067.jpg', '1137.jpg', '1053.jpg', '1166.jpg', '1109.jpg', '1155.jpg', '1132.jpg', '1054.jpg', '1172.jpg', '1095.jpg', '1083.jpg', '1154.jpg', '1160.jpg', '1112.jpg', '1106.jpg', '1096.jpg', '1117.jpg', '1135.jpg', '1040.jpg', '1041.jpg', '1068.png', '1103.png', '1133.jpg', '1107.jpg', '1110.jpg', '1136.jpg', '1058.jpg', '1159.jpg', '1173.jpg', '1246.jpg', '1255.jpg', '1409.jpg', '1369.jpg', '1290.jpg', '1195.jpg', '1247.jpg', '1394.jpg', '1264.jpg', '1346.jpg', '1234.jpg', '1340.jpg', '1243.jpg', '1383.jpg', '1291.jpg', '1251.jpg', '1405.jpg', '1406.jpg', '1339.jpg', '1278.jpg', '1378.jpg', '1323.jpg', '1279.jpg', '1214.jpg', '1338.jpg', '1280.jpg', '1514.jpg', '1520.jpg', '1455.jpg', '1487.jpg', '1503.jpg', '1513.jpg', '1511.jpg', '1548.jpg', '1539.jpg', '1453.jpg', '1462.jpg', '1527.jpg', '1488.jpg', '1523.jpg', '1536.jpg', '1553.jpg', '1530.jpg', '1555.jpg', '1493.jpg', '1518.jpg', '1490.jpg', '1491.jpg', '1471.jpg', '1492.jpg', '1515.jpg', '1512.jpg', '1486.jpg', '1554.jpg', '1456.jpg', '1473.jpg', '1517.jpg', '1526.jpg', '1506.jpg', '1430.jpg', '1568.jpg', '1577.jpg', '1689.jpg', '1558.png', '1608.jpeg', '1669.jpg', '1560.jpg', '1645.jpg', '1634.jpg', '1637.jpg', '1562.jpg', '1556.jpg', '1598.jpg', '1576.jpg', '1584.jpg', '1583.jpg', '1609.jpg', '1601.jpg', '1664.jpg', '1600.jpg', '1631.jpg', '1635.jpg', '1574.jpg', '1628.jpg', '1589.jpg', '1626.jpg', '1636.jpg']\n",
            "['0.jpg', '100.jpg', '1.jpg', '101.jpg', '102.jpg', '10.jpg', '106.jpg', '124.jpg', '123.jpg', '125.jpg', '104.jpg', '115.jpg', '127.jpg', '122.jpg', '132.jpg', '105.jpg', '134.jpg', '129.jpg', '119.jpg', '114.jpg', '131.jpg', '117.jpg', '107.jpg', '130.jpg', '12.jpg', '110.jpg', '13.jpg', '136.jpg', '137.jpg', '108.jpg', '135.jpg', '109.jpg', '11.jpg', '120.jpg', '118.jpg', '128.jpg', '116.jpg', '133.jpg', '112.jpg', '111.jpg', '160.jpg', '162.jpg', '149.jpg', '170.jpg', '16.jpg', '152.jpg', '156.jpg', '15.jpg', '138.jpg', '163.jpg', '143.jpg', '171.jpg', '161.jpg', '142.jpg', '139.jpg', '166.jpg', '141.jpg', '153.jpg', '168.jpg', '17.jpg', '146.jpg', '158.jpg', '157.jpg', '159.jpg', '148.jpg', '14.jpg', '151.jpg', '172.jpg', '154.jpg', '155.jpg', '169.jpg', '164.jpg', '145.jpg', '140.jpg', '186.jpg', '187.jpg', '196.jpg', '18.jpg', '180.jpg', '188.jpg', '195.jpg', '183.jpg', '207.jpg', '204.jpg', '175.jpg', '174.jpg', '192.jpg', '177.jpg', '206.jpg', '184.jpg', '191.jpg', '193.jpg', '179.jpg', '208.jpg', '2.jpg', '176.jpg', '197.jpg', '203.jpg', '178.jpg', '201.jpg', '185.jpg', '194.jpg', '198.jpg', '20.jpg', '19.jpg', '181.jpg', '173.jpg', '223.jpg', '231.jpg', '240.jpg', '239.jpg', '221.jpg', '210.jpg', '222.jpg', '22.jpg', '243.jpg', '232.jpg', '234.jpg', '213.jpg', '212.jpg', '226.jpg', '23.jpg', '233.jpg', '211.jpg', '225.jpg', '241.jpg', '24.jpg', '228.jpg', '220.jpg', '217.jpg', '216.jpg', '229.jpg', '215.jpg', '237.jpg', '230.jpg', '214.jpg', '224.jpg', '242.jpg', '218.jpg', '227.jpg', '269.jpg', '270.jpg', '262.jpg', '278.jpg', '253.jpg', '267.jpg', '261.jpg', '275.jpg', '263.jpg', '251.jpg', '247.jpg', '28.jpg', '266.jpg', '249.jpg', '246.jpg', '281.jpg', '276.jpg', '255.jpg', '248.jpg', '256.jpg', '271.jpg', '260.jpg', '26.jpg', '258.jpg', '244.jpg', '265.jpg', '280.jpg', '254.jpg', '259.jpg', '27.jpg', '250.jpg', '252.jpg', '264.jpg', '303.jpg', '310.jpg', '3.jpg', '291.jpg', '317.jpg', '282.jpg', '311.jpg', '30.jpg', '299.jpg', '294.jpg', '283.jpg', '307.jpg', '284.jpg', '287.jpg', '306.jpg', '288.jpg', '289.jpg', '286.jpg', '301.jpg', '298.jpg', '300.jpg', '31.jpg', '312.jpg', '297.jpg', '293.jpg', '309.jpg', '285.jpg', '315.jpg', '316.jpg', '295.jpg', '29.jpg', '302.jpg', '308.jpg', '292.jpg', '290.jpg', '329.jpg', '340.jpg', '39.jpg', '345.jpg', '341.jpg', '321.jpg', '36.jpg', '37.jpg', '339.jpg', '324.jpg', '32.jpg', '331.jpg', '348.jpg', '332.jpg', '335.jpg', '334.jpg', '33.jpg', '328.jpg', '34.jpg', '325.jpg', '336.jpg', '319.jpg', '352.jpg', '347.jpg', '326.jpg', '350.jpg', '353.jpg', '338.jpg', '322.jpg', '318.jpg', '330.jpg', '351.jpg', '327.jpg', '323.jpg', '337.jpg', '349.jpg', '344.jpg', '77.jpg', '7.jpg', '4.jpg', '48.jpg', '64.jpg', '66.jpg', '55.jpg', '76.jpg', '74.jpg', '52.jpg', '56.jpg', '73.jpg', '62.jpg', '54.jpg', '69.jpg', '49.jpg', '40.jpg', '61.jpg', '63.jpg', '57.jpg', '47.jpg', '79.jpg', '42.jpg', '43.jpg', '50.jpg', '51.jpg', '59.jpg', '58.jpg', '53.jpg', '6.jpg', '44.jpg', '46.jpg', '70.jpg', '67.jpg', '65.jpg', '45.jpg', '95.jpg', '86.jpg', '92.jpg', '81.jpg', '90.jpg', '88.jpg', '80.jpg', '99.jpg', '83.jpg', '84.jpg', '94.jpg', '98.jpg', '87.jpg', '93.jpg', '89.jpg', '96.jpg', '91.jpg', '97.jpg', '9.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   zoom_range=0.2,\n",
        "                                   rotation_range=40,\n",
        "                                   horizontal_flip=True) \n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory(train_dir,\n",
        "                                                  target_size=(150,150),\n",
        "                                                  batch_size=32,\n",
        "                                                  class_mode='binary')\n",
        "\n",
        "test_generator=test_datagen.flow_from_directory(test_dir,\n",
        "                                                target_size=(150,150),\n",
        "                                                batch_size=32,\n",
        "                                                class_mode='binary')\n",
        "\n",
        "valid_generator=validation_datagen.flow_from_directory(valid_dir,\n",
        "                                                target_size=(150,150),\n",
        "                                                batch_size=32,\n",
        "                                                class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwmxXZ92GQKz",
        "outputId": "654d00e8-9b4b-4861-f011-f71fd4c0e724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 600 images belonging to 2 classes.\n",
            "Found 100 images belonging to 2 classes.\n",
            "Found 306 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ed7R6OCGP9z",
        "outputId": "a3d6a2a2-1cf9-43da-954f-c3fe3d724b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Mask': 0, 'Non Mask': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator.image_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lJz8IM_GPwp",
        "outputId": "4f6ec4d7-18f0-46cc-dfad-c678ec1e8c56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,(3,3),padding='SAME',activation='relu',input_shape=(150,150,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), padding='SAME', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KIQ7SFeIsuB",
        "outputId": "8f8bc794-2b98-4f9c-e233-49019b998059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 150, 150, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 75, 75, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 75, 75, 32)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 75, 75, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 37, 37, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 37, 37, 64)        0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 87616)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               22429952  \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,449,601\n",
            "Trainable params: 22,449,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JargZzBGQor_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs = 30,\n",
        "                    validation_data = valid_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km7e9KX1RRH1",
        "outputId": "1095156d-b82b-40ac-f64c-5366469db85d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "19/19 [==============================] - 227s 12s/step - loss: 3.6115 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.6707 - accuracy: 0.5617 - val_loss: 0.6801 - val_accuracy: 0.6438\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.5479 - accuracy: 0.7583 - val_loss: 0.6398 - val_accuracy: 0.7582\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 37s 2s/step - loss: 0.4090 - accuracy: 0.8433 - val_loss: 0.5448 - val_accuracy: 0.7810\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.3666 - accuracy: 0.8600 - val_loss: 0.3829 - val_accuracy: 0.8529\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.3031 - accuracy: 0.8850 - val_loss: 0.4644 - val_accuracy: 0.8268\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.2897 - accuracy: 0.9050 - val_loss: 0.4149 - val_accuracy: 0.8529\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.2811 - accuracy: 0.9050 - val_loss: 0.3792 - val_accuracy: 0.8529\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.2366 - accuracy: 0.9183 - val_loss: 0.3674 - val_accuracy: 0.8464\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.2270 - accuracy: 0.9267 - val_loss: 0.2462 - val_accuracy: 0.9020\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.2411 - accuracy: 0.9167 - val_loss: 0.2821 - val_accuracy: 0.9020\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 37s 2s/step - loss: 0.2243 - accuracy: 0.9167 - val_loss: 0.3828 - val_accuracy: 0.8562\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.2276 - accuracy: 0.9017 - val_loss: 0.2549 - val_accuracy: 0.8954\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.2270 - accuracy: 0.9083 - val_loss: 0.2874 - val_accuracy: 0.8954\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.1934 - accuracy: 0.9367 - val_loss: 0.3176 - val_accuracy: 0.8824\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.2142 - accuracy: 0.9200 - val_loss: 0.2770 - val_accuracy: 0.8856\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.2130 - accuracy: 0.9117 - val_loss: 0.2532 - val_accuracy: 0.9020\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.2128 - accuracy: 0.9233 - val_loss: 0.2892 - val_accuracy: 0.8954\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.2080 - accuracy: 0.9250 - val_loss: 0.2349 - val_accuracy: 0.8987\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 39s 2s/step - loss: 0.1937 - accuracy: 0.9250 - val_loss: 0.2609 - val_accuracy: 0.8954\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 40s 2s/step - loss: 0.2121 - accuracy: 0.9200 - val_loss: 0.2746 - val_accuracy: 0.9020\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 39s 2s/step - loss: 0.1947 - accuracy: 0.9217 - val_loss: 0.2689 - val_accuracy: 0.8954\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 40s 2s/step - loss: 0.1709 - accuracy: 0.9367 - val_loss: 0.2230 - val_accuracy: 0.9085\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 40s 2s/step - loss: 0.1947 - accuracy: 0.9250 - val_loss: 0.2525 - val_accuracy: 0.9150\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 40s 2s/step - loss: 0.1810 - accuracy: 0.9383 - val_loss: 0.2436 - val_accuracy: 0.9020\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 41s 2s/step - loss: 0.1728 - accuracy: 0.9267 - val_loss: 0.2280 - val_accuracy: 0.9052\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.1984 - accuracy: 0.9217 - val_loss: 0.2365 - val_accuracy: 0.9216\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.1734 - accuracy: 0.9367 - val_loss: 0.2502 - val_accuracy: 0.9052\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.1803 - accuracy: 0.9300 - val_loss: 0.2425 - val_accuracy: 0.9085\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 38s 2s/step - loss: 0.1681 - accuracy: 0.9367 - val_loss: 0.2400 - val_accuracy: 0.9118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss , test_acc = model.evaluate(test_generator)\n",
        "print('test acc :{} test loss :{}'.format(test_acc,test_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl1HpDeVSLO9",
        "outputId": "90dea6cb-40b5-4cda-867d-6c59ec6d1e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 18s 6s/step - loss: 0.2061 - accuracy: 0.9000\n",
            "test acc :0.8999999761581421 test loss :0.20606735348701477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('newsaved_model.h5')"
      ],
      "metadata": {
        "id": "SOVhw6yjSjB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "model = load_model('newsaved_model.h5')\n",
        "\n",
        "img_width, img_height = 150,150\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "#cap = cv2.VideoCapture('video.mp4')\n",
        "cap = cv2.VideoCapture(0)\n",
        "img_count_full = 0\n",
        "\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "org = (1,1)\n",
        "class_label = ''\n",
        "fontScale = 1\n",
        "color = (255,0,0)\n",
        "thickness = 2\n",
        "\n",
        "while True:\n",
        "  img_count_full += 1\n",
        "  response , color_img = cap.read()\n",
        "\n",
        "  if response == False:\n",
        "    break\n",
        "\n",
        "  scale = 50\n",
        "  width = int(color_img.shape[1]*scale/100)\n",
        "  height = int(color_img.shape[0]*scale/100)\n",
        "  dim = (width,height)\n",
        "\n",
        "  color_img = cv2.resize(color_img, dim, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "  gray_img = cv2.cvtColor(color_img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  faces = face_cascade.detectMultiScale(gray_img,1.1,6)\n",
        "\n",
        "  img_count = 0\n",
        "  for (x,y,w,h) in faces:\n",
        "    org = (x-10,y-10)\n",
        "    img_count += 1\n",
        "    color_face = color_img[y:y+h,x:x+w]\n",
        "    cv2.imwrite('content/%d%dface.jpg'%(img_count_full,img_count),color_face)\n",
        "    img = load_img('/content/%d%dface.jpg'%(img_count_full,img_count),target_size=(img_width,img_height))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img,axis=0)\n",
        "    prediction = model.predict(img)\n",
        "\n",
        "\n",
        "    if prediction == 0:\n",
        "      class_label = \"Mask\"\n",
        "      color = (0,255,0)\n",
        "\n",
        "    else:\n",
        "      class_label = \"No Mask\"\n",
        "      color = (0,255,0)\n",
        "    \n",
        "    \n",
        "    cv2.rectangle(color_img,(x,y),(x+w,y+h),(255,0,0),3)\n",
        "    cv2.putText(color_img, class_label, org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
        "\n",
        "  cv2.imshow('Face mask detecton',color_img)\n",
        "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "    break\n",
        "  \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "S6Qs8LNDdBHD"
      },
      "execution_count": 76,
      "outputs": []
    }
  ]
}